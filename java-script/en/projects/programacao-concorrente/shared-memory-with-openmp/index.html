<!DOCTYPE html>
<html>

    <head>
    <meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Concurrent and Distributed Programming (5) - Dudevictor GitHub IO</title>
    <meta name="description" content="Aspirante a Engenheiro de Computação e formado em Ciências e Tecnologia pela UFRN. Desenvolvedor Java Web na Logique Sistemas.">

    <link rel="profile" href="http://gmpg.org/xfn/11"/>
    <link rel="stylesheet" href="/css/bootstrap.min.css">
    <link rel="stylesheet" href="/css/font-awesome.css">
    <link rel="stylesheet" type="text/css" media="all" href="/css/style.css"/>
    <link rel="stylesheet" type="text/css" media="all" href="/css/jquery.mmenu.all.css"/>
    <link rel="stylesheet" href="/css/androidstudio.css">
    <link rel="stylesheet" href="/css/toc.css">

    <!-- Favicons generated at http://realfavicongenerator.net/ -->
    <link rel="apple-touch-icon" sizes="57x57" href="/favicons/apple-touch-icon-57x57.png">
    <link rel="apple-touch-icon" sizes="60x60" href="/favicons/apple-touch-icon-60x60.png">
    <link rel="apple-touch-icon" sizes="72x72" href="/favicons/apple-touch-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="76x76" href="/favicons/apple-touch-icon-76x76.png">
    <link rel="apple-touch-icon" sizes="114x114" href="/favicons/apple-touch-icon-114x114.png">
    <link rel="apple-touch-icon" sizes="120x120" href="/favicons/apple-touch-icon-120x120.png">
    <link rel="apple-touch-icon" sizes="144x144" href="/favicons/apple-touch-icon-144x144.png">
    <link rel="apple-touch-icon" sizes="152x152" href="/favicons/apple-touch-icon-152x152.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/favicons/apple-touch-icon-180x180.png">
    <link rel="icon" type="image/png" href="/favicons/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="/favicons/android-chrome-192x192.png" sizes="192x192">
    <link rel="icon" type="image/png" href="/favicons/favicon-96x96.png" sizes="96x96">
    <link rel="icon" type="image/png" href="/favicons/favicon-16x16.png" sizes="16x16">
    <link rel="manifest" href="/favicons/manifest.json">
    <link rel="shortcut icon" href="/favicons/favicon.ico">
    <meta name="msapplication-TileColor" content="#da532c">
    <meta name="msapplication-TileImage" content="/favicons/mstile-144x144.png">
    <meta name="msapplication-config" content="/favicons/browserconfig.xml">
    <meta name="theme-color" content="#ffffff">
    <meta http-equiv="Content-Language" content="en">

    <link rel="alternate"
          hreflang="pt-BR"
          href="http://dudevictor.github.io"/>
    
    
    
    
    <link rel="alternate"
          hreflang="en"
          href="http://dudevictor.github.io/en"/>
    

    
    <!-- Go to www.addthis.com/dashboard to customize your tools -->
    <script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-56d8c061351eac81"></script>
    

    
    <script type="text/javascript">
        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-74364829-1']);
        _gaq.push(['_trackPageview']);
        (function () {
            var ga = document.createElement('script');
            ga.type = 'text/javascript';
            ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';

            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(ga, s);
        })();
    </script>
    
</head>


    <body>

    <nav id="my-menu">
  <div>
    <ul class="pages">
      <li><a href="/en "><i class="fa fa-home"></i> Home</a></li>
      <li>
        <span><i class="fa fa-archive"></i> All Projects</span>
        <ul>
        
          <li><a href="/en/projects/processamento-digital-imagens/ "><i class="fa fa-picture-o"></i>
            Digital Image Processing</a></li>
        
          <li><a href="/en/projects/programacao-concorrente/ "><i class="fa fa-laptop"></i>
            Concurrent and Distributed Programming</a></li>
        
          <li><a href="/en/projects/controle-inteligente/ "><i class="fa fa-globe"></i>
            Inteligent Control - A* Algotithm</a></li>
        
        </ul>
      </li>
      <li><a href=" /en/posts/"><i class="fa fa-file-text"></i> All Articles</a></li>
      <li><a href=" /en/search/"><i class="fa fa-search"></i> Search</a></li>
    </ul>

    <p class="links">
  
  <a href="https://br.linkedin.com/in/jvictoralves" target="_new"><i class="fa fa-linkedin"></i></a>
  <a href="https://github.com/dudevictor" target="_new"><i class="fa fa-github-alt"></i></a>
  <a href="https://fb.com/dudevictor" target="_new"><i class="fa fa-facebook"></i></a>
  <a href="https://plus.google.com/103774151163089217676" target="_new"><i class="fa fa-google-plus"></i></a>
  <a href="http://stackoverflow.com/users/2327056/jose-victor?tab=profile" target="_new"><i class="fa fa-stack-overflow"></i></a>
</p>

  </div>
</nav>
<div class="menu-button" href="#menu"><i class="fa fa-bars"></i></div>


    <div class="page-content">
      <div class="wrap">
      <div class="container-fluid single">
  <div class="row">

    <div itemscope itemtype="http://schema.org/Article" class="col-md-12 project">
      
      <div class="thumb">
        <i class="fa fa-laptop fa-4x"></i>
      </div>
      

      <h1 class="header" itemprop="name">Concurrent and Distributed Programming (5)</h1>

      <div class="author">
        <small><i>
          
          by
          <span itemprop="author">
            
              <a rel="author" href="https://plus.google.com/103774151163089217676">
            
            <span itemprop="author" itemscope itemtype="http://schema.org/Person">
              <span itemprop="name">José Victor Alves de Souza</span>
            </span>
            
              </a>
            
          </span>
          
          on <span itemprop="datePublished" content="2014-08-28">April 09, 2016</span>
        </i></small>
      </div>

      <div class="read-time">
        <small>
          Prof. Samuel Xavier de Souza, Departamento de Engenharia de Computação, UFRN 2015.2
        </small>
      </div>

      <div class="anuncio-cabecalho">
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <!-- Cabeçalho Responsivo -->
    <ins class="adsbygoogle"
         style="display:block"
         data-ad-client="ca-pub-9976909752880073"
         data-ad-slot="1413881545"
         data-ad-format="auto"></ins>
    <script>
        (adsbygoogle = window.adsbygoogle || []).push({});
    </script>
    
</div>

      <div class="content-panel content">
        <span itemprop="articleBody"><p>Esta página tem como objetivo apresentar a resolução dos exercícios do livro <a href="https://www.cs.usfca.edu/%7Epeter/ipp/">&quot;An Introduction to Parallel Programming&quot;</a>
de Peter Pacheco. A resolução dessas listas foi utilizada durante o curso de Programação Paralela no DCA / UFRN.</p>

<p>Respostas dos capítulos:</p>

<ul>
<li><p><a href="/en/projects/programacao-concorrente/">Chapter 01 - Why Parallel Computing?</a></p></li>
<li><p><a href="/en/projects/programacao-concorrente/parallel-hardware-and-parallel-software/">Chapter 02 - Parallel Hardware and Parallel Software</a></p></li>
<li><p><a href="/en/projects/programacao-concorrente/distributed-memory-programming/">Chapter 03 - Distributed-Memory Programming with MPI</a></p></li>
<li><p><a href="/en/projects/programacao-concorrente/shared-memory-with-pthreads/">Chapter 04 - Shared-Memory Programming with Pthreads</a></p></li>
<li><p>Chapter 05 - Shared-Memory Programming with OpenMP</p></li>
</ul>

<p></span></p>

<div class="tags">
    <small>
        <i class="fa fa-tags"></i>
        programação paralela, threads, MPI, OpenMP, DCA, UFRN, solucionário, exercises solutions, manual solutions, Parallel Programing, Peter Pacheco, Samuel Xavier de Souza
    </small>
</div>

<p></div></p>

<p><div class="content-panel content">
    <span itemprop="articleBody"></p>

<h4>Chapter 05 - Shared-Memory Programming with OpenMP</h4>

<blockquote>
<p><strong>5.1</strong> Use OpenMP to implement the parallel histogram program discussed in
         Chapter 2.</p>
</blockquote>

<p><a href="/assets/codes-copyright/histogram_5_1.c">Código Implementado</a><br></p>
<div class="highlight"><pre><code class="language-c" data-lang="c"><span class="cm">/*---------------------------------------------------------------------
 * Function:  Gen_bins
 * Purpose:   Compute max value for each bin, and store 0 as the
 *            number of values in each bin
 * In args:   min_meas:   the minimum possible measurement
 *            max_meas:   the maximum possible measurement
 *            bin_count:  the number of bins
 * Out args:  bin_maxes:  the maximum possible value for each bin
 *            bin_counts: the number of data values in each bin
 */</span>
<span class="kt">void</span> <span class="nf">Gen_bins</span><span class="p">(</span>
      <span class="kt">float</span> <span class="n">min_meas</span>      <span class="cm">/* in  */</span><span class="p">,</span> 
      <span class="kt">float</span> <span class="n">max_meas</span>      <span class="cm">/* in  */</span><span class="p">,</span> 
      <span class="kt">float</span> <span class="n">bin_maxes</span><span class="p">[]</span>   <span class="cm">/* out */</span><span class="p">,</span> 
      <span class="kt">int</span>   <span class="n">bin_counts</span><span class="p">[]</span>  <span class="cm">/* out */</span><span class="p">,</span> 
      <span class="kt">int</span>   <span class="n">bin_count</span>     <span class="cm">/* in  */</span><span class="p">)</span> <span class="p">{</span>
   <span class="kt">float</span> <span class="n">bin_width</span><span class="p">;</span>
   <span class="kt">int</span>   <span class="n">i</span><span class="p">;</span>

   <span class="n">bin_width</span> <span class="o">=</span> <span class="p">(</span><span class="n">max_meas</span> <span class="o">-</span> <span class="n">min_meas</span><span class="p">)</span><span class="o">/</span><span class="n">bin_count</span><span class="p">;</span>

   <span class="cp">#pragma omp parallel for num_threads(thread_count) \
      default(none) \
      shared(min_meas, max_meas, bin_maxes, bin_counts, bin_count, bin_width) \
      private(i)
</span>   <span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">bin_count</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">bin_maxes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">min_meas</span> <span class="o">+</span> <span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">bin_width</span><span class="p">;</span>
      <span class="n">bin_counts</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
   <span class="p">}</span>

<span class="cp">#  ifdef DEBUG
</span>   <span class="n">printf</span><span class="p">(</span><span class="s">"bin_maxes = "</span><span class="p">);</span>
   <span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">bin_count</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>
      <span class="n">printf</span><span class="p">(</span><span class="s">"%4.3f "</span><span class="p">,</span> <span class="n">bin_maxes</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
   <span class="n">printf</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
<span class="cp">#  endif
</span><span class="p">}</span>  <span class="cm">/* Gen_bins */</span>

<span class="cm">/*---------------------------------------------------------------------
 * Function:  Gen_data
 * Purpose:   Generate random floats in the range min_meas &lt;= x &lt; max_meas
 * In args:   min_meas:    the minimum possible value for the data
 *            max_meas:    the maximum possible value for the data
 *            data_count:  the number of measurements
 * Out arg:   data:        the actual measurements
 */</span>
<span class="kt">void</span> <span class="nf">Gen_data</span><span class="p">(</span>
        <span class="kt">float</span>   <span class="n">min_meas</span>    <span class="cm">/* in  */</span><span class="p">,</span> 
        <span class="kt">float</span>   <span class="n">max_meas</span>    <span class="cm">/* in  */</span><span class="p">,</span> 
        <span class="kt">float</span>   <span class="n">data</span><span class="p">[]</span>      <span class="cm">/* out */</span><span class="p">,</span>
        <span class="kt">int</span>     <span class="n">data_count</span>  <span class="cm">/* in  */</span><span class="p">)</span> <span class="p">{</span>
   <span class="kt">int</span> <span class="n">i</span><span class="p">;</span>

   <span class="n">srandom</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
   <span class="cp">#pragma omp parallel for num_threads(thread_count) \
      default(none) shared(data, min_meas, max_meas, data_count)
</span>      <span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">data_count</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
         <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">min_meas</span> <span class="o">+</span> <span class="p">(</span><span class="n">max_meas</span> <span class="o">-</span> <span class="n">min_meas</span><span class="p">)</span> <span class="o">*</span> <span class="n">random</span><span class="p">()</span> <span class="o">/</span> <span class="p">((</span><span class="kt">double</span><span class="p">)</span> <span class="n">RAND_MAX</span><span class="p">);</span>
      <span class="p">}</span>

<span class="cp">#  ifdef DEBUG
</span>   <span class="n">printf</span><span class="p">(</span><span class="s">"data = "</span><span class="p">);</span>
   <span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">data_count</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>
      <span class="n">printf</span><span class="p">(</span><span class="s">"%4.3f "</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
   <span class="n">printf</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
<span class="cp">#  endif
</span><span class="p">}</span>  <span class="cm">/* Gen_data */</span>

</code></pre></div><div class="highlight"><pre><code class="language-c" data-lang="c"><span class="cm">/* Count number of values in each bin */</span>
   <span class="cp">#pragma omp parallel for num_threads(thread_count) default(none) \
      shared(data_count, data, bin_maxes, bin_count, min_meas, bin_counts) \
      private(bin, i)
</span>   <span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">data_count</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">bin</span> <span class="o">=</span> <span class="n">Which_bin</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">bin_maxes</span><span class="p">,</span> <span class="n">bin_count</span><span class="p">,</span> <span class="n">min_meas</span><span class="p">);</span>
      <span class="cp">#pragma omp critical
</span>      <span class="n">bin_counts</span><span class="p">[</span><span class="n">bin</span><span class="p">]</span><span class="o">++</span><span class="p">;</span>
   <span class="p">}</span>
</code></pre></div>
<p><img src="/assets/pcd/img5.1.png" alt="Imagem5.1"></p>

<blockquote>
<p><strong>5.2.</strong> Suppose we toss darts randomly at a square dartboard, whose bullseye is at the
          origin, and whose sides are 2 feet in length. Suppose also that there’s a circle
          inscribed in the square dartboard. The radius of the circle is 1 foot, and it’s area
          is π square feet. If the points that are hit by the darts are uniformly distributed
          (and we always hit the square), then the number of darts that hit inside the circle
          should approximately satisfy the equation.<br>
$$ \frac{number\ in\ circle}{total\ number\ of\ tosses} = \frac{\pi}{4} $$
since the ratio of the area of the circle to the area of the square is π/4.
We can use this formula to estimate the value of π with a random number
generator:</p>
<div class="highlight"><pre><code class="language-c" data-lang="c"><span class="n">number</span> <span class="n">in</span> <span class="n">circle</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
<span class="k">for</span> <span class="p">(</span> <span class="n">toss</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">toss</span> <span class="o">&lt;</span> <span class="n">number</span> <span class="n">of</span> <span class="n">tosses</span> <span class="p">;</span> <span class="n">toss</span> <span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">random</span> <span class="kt">double</span> <span class="n">between</span> <span class="err">−</span> <span class="mi">1</span> <span class="n">and</span> <span class="mi">1</span><span class="p">;</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">random</span> <span class="kt">double</span> <span class="n">between</span> <span class="err">−</span> <span class="mi">1</span> <span class="n">and</span> <span class="mi">1</span><span class="p">;</span>
    <span class="n">distance</span> <span class="n">squared</span> <span class="o">=</span> <span class="n">x</span> <span class="err">∗</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span> <span class="err">∗</span> <span class="n">y</span> <span class="p">;</span>
    <span class="k">if</span> <span class="p">(</span> <span class="n">distance</span> <span class="n">squared</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">)</span> <span class="n">number</span> <span class="n">in</span> <span class="n">circle</span> <span class="o">++</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">pi</span> <span class="n">estimate</span> <span class="o">=</span> <span class="mi">4</span><span class="err">∗</span> <span class="n">number</span> <span class="n">in</span> <span class="n">circle</span> <span class="o">/</span><span class="p">((</span><span class="kt">double</span><span class="p">)</span> <span class="n">number</span> <span class="n">of</span> <span class="n">tosses</span> <span class="p">);</span>
</code></pre></div>
<p>This is called a “Monte Carlo” method, since it uses randomness (the dart tosses).
 Write an OpenMP program that uses a Monte Carlo method to estimate π. Read in the total 
 number of tosses before forking any threads. Use a reduction clause to find the 
 total number of darts hitting inside the circle. Print the result after joining 
 all the threads. You may want to use long long int s for 
 the number of hits in the circle and the number of tosses, 
 since both may have to be very large to get a reasonable estimate of π.</p>
</blockquote>

<p><a href="/assets/codes-copyright/program_5_2.c">Código Implementado</a><br></p>
<div class="highlight"><pre><code class="language-c++" data-lang="c++">   <span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span><span class="o">*</span> <span class="n">argv</span><span class="p">[])</span> <span class="p">{</span>
   <span class="kt">long</span> <span class="kt">int</span> <span class="n">number_tosses</span><span class="p">,</span> <span class="n">number_in_circle</span><span class="p">;</span>
   <span class="kt">int</span> <span class="n">thread_count</span><span class="p">,</span> <span class="n">i</span><span class="p">;</span>
   <span class="kt">double</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">distancia</span><span class="p">;</span>

   <span class="k">if</span> <span class="p">(</span><span class="n">argc</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">)</span> <span class="n">Usage</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>
   <span class="n">thread_count</span> <span class="o">=</span> <span class="n">strtol</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="nb">NULL</span><span class="p">,</span> <span class="mi">10</span><span class="p">);</span>
   <span class="n">number_tosses</span> <span class="o">=</span> <span class="n">strtoll</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="nb">NULL</span><span class="p">,</span> <span class="mi">10</span><span class="p">);</span>
   <span class="k">if</span> <span class="p">(</span><span class="n">thread_count</span> <span class="o">&lt;</span> <span class="mi">1</span> <span class="o">||</span> <span class="n">number_tosses</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">)</span> <span class="n">Usage</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>

   <span class="n">number_in_circle</span> <span class="o">=</span><span class="mi">0</span><span class="p">;</span>
   <span class="n">srandom</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="cp">#  pragma omp parallel for num_threads(thread_count) \
      reduction(+: number_in_circle) private(x, y, distancia)
</span>   <span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">number_tosses</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">x</span> <span class="o">=</span> <span class="n">num_aleatorio</span><span class="p">();</span> <span class="c1">// Gera nnumero entre -1 e 1
</span>      <span class="n">y</span> <span class="o">=</span> <span class="n">num_aleatorio</span><span class="p">();</span>
      <span class="n">distancia</span> <span class="o">=</span> <span class="n">x</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="n">y</span><span class="o">*</span><span class="n">y</span><span class="p">;</span>

      <span class="k">if</span> <span class="p">(</span><span class="n">distancia</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
         <span class="n">number_in_circle</span> <span class="o">+=</span> <span class="mi">1</span><span class="p">;</span>
      <span class="p">}</span>
   <span class="p">}</span>
   <span class="kt">double</span> <span class="n">pi</span> <span class="o">=</span> <span class="mi">4</span><span class="o">*</span><span class="n">number_in_circle</span><span class="o">/</span><span class="p">((</span><span class="kt">double</span><span class="p">)</span> <span class="n">number_tosses</span><span class="p">);</span>
   <span class="n">printf</span><span class="p">(</span><span class="s">"Estimacao de pi = %.14f</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">pi</span><span class="p">);</span>
   <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>  <span class="cm">/* main */</span>
</code></pre></div>
<p><img src="/assets/pcd/img5.2.png" alt="Imagem5.2"></p>

<blockquote>
<p><strong>5.3.</strong> Count sort is a simple serial sorting algorithm that can be implemented as
   follows:</p>
<div class="highlight"><pre><code class="language-c" data-lang="c"><span class="kt">void</span> <span class="n">Count</span> <span class="nf">sort</span> <span class="p">(</span><span class="kt">int</span> <span class="n">a</span> <span class="p">[],</span> <span class="kt">int</span> <span class="n">n</span> <span class="p">)</span> <span class="p">{</span>
<span class="kt">int</span> <span class="n">i</span> <span class="p">,</span> <span class="n">j</span> <span class="p">,</span> <span class="n">count</span> <span class="p">;</span>
<span class="kt">int</span><span class="err">∗</span> <span class="n">temp</span> <span class="o">=</span> <span class="n">malloc</span> <span class="p">(</span> <span class="n">n</span> <span class="err">∗</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>
<span class="k">for</span> <span class="p">(</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">n</span> <span class="p">;</span> <span class="n">i</span> <span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="k">for</span> <span class="p">(</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">n</span> <span class="p">;</span> <span class="n">j</span> <span class="o">++</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span> <span class="n">a</span> <span class="p">[</span> <span class="n">j</span> <span class="p">]</span> <span class="o">&lt;</span> <span class="n">a</span> <span class="p">[</span> <span class="n">i</span> <span class="p">])</span>
            <span class="n">count</span> <span class="o">++</span><span class="p">;</span>
        <span class="k">else</span> <span class="k">if</span> <span class="p">(</span> <span class="n">a</span> <span class="p">[</span> <span class="n">j</span> <span class="p">]</span> <span class="o">==</span> <span class="n">a</span> <span class="p">[</span> <span class="n">i</span> <span class="p">]</span> <span class="o">&amp;&amp;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">i</span> <span class="p">)</span>
            <span class="n">count</span> <span class="o">++</span><span class="p">;</span>
    <span class="n">temp</span> <span class="p">[</span> <span class="n">count</span> <span class="p">]</span> <span class="o">=</span> <span class="n">a</span> <span class="p">[</span> <span class="n">i</span> <span class="p">];</span>
<span class="p">}</span>
<span class="n">memcpy</span> <span class="p">(</span> <span class="n">a</span> <span class="p">,</span> <span class="n">temp</span> <span class="p">,</span> <span class="n">n</span> <span class="err">∗</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>
<span class="n">free</span> <span class="p">(</span> <span class="n">temp</span> <span class="p">);</span>
<span class="p">}</span>
<span class="o">/</span><span class="err">∗</span> <span class="n">Count</span> <span class="n">sort</span> <span class="err">∗</span><span class="o">/</span>
</code></pre></div>
<p>The basic idea is that for each element a[i] in the list a , we count the num-
 ber of elements in the list that are less than a[i] . Then we insert a[i] into
 a temporary list using the subscript determined by the count. There’s a slight
 problem with this approach when the list contains equal elements, since they
 could get assigned to the same slot in the temporary list. The code deals with
 this by incrementing the count for equal elements on the basis of the subscripts.
 If both a[i] == a[j] and j &lt;i , then we count a[j] as being “less than” a[i] .
 After the algorithm has completed, we overwrite the original array with the
 temporary array using the string library function memcpy .</p>

<p><strong>a.</strong> If we try to parallelize the for i loop (the outer loop), which variables
 should be private and which should be shared?</p>
</blockquote>

<p>As variáveis a e n devem ser compartilhadas, já que seria necessário acessar a 
variável a e ter acesso ao seu tamanho. A variável temp também seria compartilhada, 
umas vez que cada posição do array só seria escrita por uma única thread. 
As variáveis i, j, count deveriam ser privadas.</p>

<blockquote>
<p><strong>b.</strong> If we parallelize the for i loop using the scoping you specified in 
the previous part, are there any loop-carried dependences? Explain your answer.</p>
</blockquote>

<p>Não, não haveria nenhuma dependência entre as iterações uma vez que não seria 
necessário ter acesso a uma informação de uma outra iteração durante a execução do 
código. Além disso, a variável temp pode ser escrita pelas threads sem gerar problemas de concorrência.</p>

<blockquote>
<p><strong>c.</strong> Can we parallelize the call to memcpy ? Can we modify the code so that this
   part of the function will be parallelizable?</p>
</blockquote>

<p>Sim, a chamada ao memcpy também poderia ser paralelizada. 
A única preocupação seria em relação ao tamanho de n que não deveria ser o mesmo. 
Além disso, o primeiro e o segundo argumento da função memcpy, deveria ser ponteiros para 
elementos do array a partir do qual deveria comecar a escrita. Segue o exemplo do código:</p>

<p><img src="/assets/pcd/img5.3.png" alt="Imagem5.3"></p>

<blockquote>
<p><strong>d.</strong> Write a C program that includes a parallel implementation of Count sort .</p>
</blockquote>

<p><a href="/assets/codes-copyright/program_5_3.c">Código Implementado</a><br></p>
<div class="highlight"><pre><code class="language-" data-lang="">int main(int argc, char* argv[]) {
   long int number_tosses, number_in_circle;
   int thread_count, i, j, n, count;
   srandom(0);
   thread_count = strtol(argv[1], NULL, 10);
   n = strtol(argv[2], NULL, 10);
   int * a = malloc(n* sizeof(int));
   geraMatriz(a, n);
   //imprimeMatriz(a, n);
   int * temp = malloc(n* sizeof(int));
   double start = omp_get_wtime();
#pragma omp parallel for num_threads(thread_count) \
   default(none) private(i, j, count) shared(a, n, temp, thread_count)
      for (i = 0; i &lt; n; i++) {
         count = 0;
         for (j = 0; j &lt; n; j++)
            if (a[j] &lt; a[i])
               count++;
            else if (a[j] == a[i] &amp;&amp; j &lt; i)
               count++;
         temp[count] = a[i];
      }
   memcpy ( a , temp, n * sizeof(int));
   double finish = omp_get_wtime();
   free(temp );
   printf("Tempo estimado %e segundos\n", finish - start);
   //imprimeMatriz(a, n);
   return 0;
}  /* main */
</code></pre></div>
<blockquote>
<p><strong>e.</strong> How does the performance of your parallelization of Count sort 
compare to serial Count sort? How does it compare to the serial qsort library function?</p>
</blockquote>

<p><img src="/assets/pcd/img5.3.e.png" alt="Imagem5.3.e"></p>

<p>O quicksort possui complexidade de nlog(n) no melhor caso e no caso médio, 
e n² no pior caso, em comparação com o algoritmo n² do método count_sort apresentado.</p>

<blockquote>
<p><strong>5.4.</strong> Recall that when we solve a large linear system, we often use 
Gaussian elimination followed by backward substitution. Gaussian elimination converts 
an n × n linear system into an upper triangular linear system by using the “row
   operations.”</p>

<p>...</p>

<p><strong>a.</strong> Determine whether the outer loop of the row-oriented algorithm can be
 parallelized.</p>
</blockquote>

<p>O loop mais externo não é possível de ser paralelizado uma vez que existe 
dependências entre as iterações. O sistema é resolvido de baixo para cima 
(da última linha até a primeira) e o resultados das linhas mais abaixo são 
utilizadas para saber o resultado das linhas mais acima.</p>

<blockquote>
<p><strong>b.</strong> Determine whether the inner loop of the row-oriented algorithm can be
   parallelized.</p>
</blockquote>

<p>O loop mais interno é capaz de ser paralelizado, no entanto, 
existe uma região crítica ao realizar o procedimento “x[row] -=” 
fazendo com que apenas uma thread realize a subtração por vez.   </p>

<blockquote>
<p><strong>c.</strong> Determine whether the (second) outer loop of the column-oriented algorithm
can be parallelized.</p>
</blockquote>

<p>O loop mais externo não é possível de ser paralelizado pois 
existe dependência entre as iterações, pois os loops seguintes necessitam 
que seja executado a subtração realizada nos loops anteriores para poder proceder.</p>

<blockquote>
<p><strong>d.</strong> Determine whether the inner loop of the column-oriented algorithm can be
   parallelized.</p>
</blockquote>

<p>O loop mais interno é possível sim de ser paralizado. 
Nesse caso não existe a região crítica como no caso do row-oriented.</p>

<blockquote>
<p><strong>e</strong> Write one OpenMP program for each of the loops that you determined could
       be parallelized. You may find the single directive useful—when a block
       of code is being executed in parallel and a sub-block should be executed by
       only one thread, the sub-block can be modified by a #pragma omp single
       directive. The threads in the executing team will block at the end of the
       directive until all of the threads have completed it.</p>
</blockquote>

<p>Row Oriented:</p>

<p><a href="/assets/codes-copyright/row_oriented_5_4.c">Código Implementado - Row Oriented</a><br></p>
<div class="highlight"><pre><code class="language-" data-lang="">for (row = n - 1; row &gt;= 0; row--) {
      x[row] = b[row];

      #pragma omp parallel for num_threads(thread_count) default(none) \
         private(col) shared(x, b, a, n, row)
      for (col = row + 1; col &lt; n ; col++) {
         double valor = a[row*n + col]*x[col];
         #pragma omp critical
         x[row] -= valor;
      }

      x[row] /= a[row*n + row];
}
</code></pre></div>
<p>Col Oriented:</p>

<p><a href="/assets/codes-copyright/col_oriented_5_4.c">Código Implementado - Col Oriented</a><br></p>
<div class="highlight"><pre><code class="language-" data-lang="">#pragma omp parallel for num_threads(thread_count) default(none) \
         private(row) shared(x, b, n)
   for (row = 0; row &lt; n; row++) {
      x[row] = b[row];
   }


   for (col = n -1; col &gt;= 0; col--) {
      x[col] /= a[col*n + col];

      #pragma omp parallel for num_threads(thread_count) default(none) \
         private(row) shared(x, b, a, n, col)
      for (row = 0; row &lt; col; row++) {
         x[row] -= a[row*n + col]*x[col];
      }
   }
</code></pre></div>
<blockquote>
<p><strong>f.</strong> Modify your parallel loop with a schedule(runtime) clause and test the
   program with various schedules. If your upper triangular system has 10,000
   variables, which schedule gives the best performance?</p>
</blockquote>

<p><img src="/assets/pcd/img5.4.f.png" alt="Imagem5.4.f"></p>

<p>O que obteve melhor performance foi a execução default. 
O static obteve resultados próximos ao default, no entanto não conseguiu 
obter um resultado melhor. A pior execução foi o dynamic, pois ele adiciona 
overhead no sistema, pois os índices são definidos em tempo de execução. 
O guided obteve um bom resultado em relação ao dynamic, mas pior em relação ao static.</p>

<blockquote>
<p><strong><div class='text-danger'>5.5.</div></strong></p>
</blockquote>

<p></p>

<blockquote>
<p><strong>5.6</strong> Write an OpenMP program that determines the default scheduling 
of parallel for loops. Its input should be the number of iterations, 
and its output should be which iterations of a parallelized for loop 
are executed by which thread. For example, if there are two threads and 
four iterations, the output might be:</p>

<p><code>Thread 0: Iterations 0 - 1</code></p>

<p><code>Thread 1: Iterations 2 - 3</code></p>
</blockquote>

<p><a href="/assets/codes-copyright/PCD_5.6.c">Código Implementado</a><br></p>
<div class="highlight"><pre><code class="language-" data-lang="">int main(int argc, char *argv[]) {
    long thread_count;
    int i, iteracoes;

    thread_count = strtol(argv[1], NULL, 10);

    printf("Insira a quantidade de iterações: ");
    scanf("%d", &amp;iteracoes);
    printf("\n");

    # pragma omp parallel num_threads(thread_count)

        # pragma omp for

            for (i = 0; i &lt; iteracoes; ++i) {
                printf("Thread %d - Iteração %d\n", omp_get_thread_num(), i);
            }

    return 0;
}
</code></pre></div>
<p><img src="/assets/pcd/img5.6.png" alt="Imagem5.6"></p>

<blockquote>
<p><strong>5.7.</strong> In our first attempt to parallelize the program for estimating π, our program
   was incorrect. In fact, we used the result of the program when it was run with
   one thread as evidence that the program run with two threads was incorrect.
   Explain why we could “trust” the result of the program when it was run with
   one thread.</p>
</blockquote>

<p>Quando o programa é executado com uma thread, a diretiva parallel não tem efeito, 
e o programa executa da mesma forma que o programa serial anterior. 
Assim, não há loop-carried dependence, já que existe apenas uma thread.</p>

<blockquote>
<p><strong>5.8.</strong> Consider the loop</p>
<div class="highlight"><pre><code class="language-c" data-lang="c"><span class="n">a</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
 <span class="k">for</span> <span class="p">(</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">n</span> <span class="p">;</span> <span class="n">i</span> <span class="o">++</span><span class="p">)</span>
 <span class="n">a</span> <span class="p">[</span> <span class="n">i</span> <span class="p">]</span> <span class="o">=</span> <span class="n">a</span> <span class="p">[</span> <span class="n">i</span> <span class="err">−</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">i</span> <span class="p">;</span>
</code></pre></div>
<p>There’s clearly a loop-carried dependence, as the value of a[i] can’t be com-
puted without the value of a[i − 1]. Can you see a way to eliminate this
dependence and parallelize the loop?</p>
</blockquote>

<p>Fazendo o resultado de a[i] temos:
a[0] = 0
a[1] = a[0] + 1 = 0 + 1
a[2] = a[1] + 2 = 0 + 1 + 2
a[3] = a[2] + 3 = 0 + 1 + 2 + 3
a[4] = a[3] + 4 = 0 + 1 + 2 + 3 + 4</p>

<p>O comportamento desse resultado pode ser representado pelo somatório:</p>

<p><img src="/assets/pcd/img5.8.1.png" alt="Imagem5.8.1"></p>

<p>que é igual a:</p>

<p><img src="/assets/pcd/img5.8.2.png" alt="Imagem5.8.2"></p>

<p>Logo o algoritmo se torna:</p>
<div class="highlight"><pre><code class="language-" data-lang="">for (i = 0; i &lt; n; i++) {
    a[i] = i * (i + 1) / 2;
}
</code></pre></div>
<p>Neste loop o resultado de qualquer iteração não é usado novamente. 
Então o código pode ser paralelizado com a diretiva parallel for:</p>
<div class="highlight"><pre><code class="language-" data-lang="">#pragma omp parallel for num_threads(thread_count) \
    default(none) private(i) shared(a, n)
for (i = 0; i &lt; n; i++) {
    a[i] = i * (i + 1) / 2;
}
</code></pre></div>
<blockquote>
<p><strong>5.9.</strong> Modify the trapezoidal rule program that uses a parallel for directive
   ( omp trap 3.c ) so that the parallel for is modified by a schedule(runtime)
   clause. Run the program with various assignments to the environment variable
   OMP SCHEDULE and determine which iterations are assigned to which thread.
   This can be done by allocating an array iterations of n int s and in the
   Trap function assigning omp get thread num () to iterations [ i ] in the ith
   iteration of the for loop. What is the default assignment of iterations on your
   system? How are guided schedules determined?</p>
</blockquote>

<p>No sistema utilizado se nenhuma clausula schedule for utilizada, 
o escalonamento padrão é aproximadamente uma partição em blocos. 
O sistema atribui um pouco mais de trabalho à thread 0 e um pouco menos à thread thread_count - 1.</p>

<p><a href="/assets/codes-copyright/PCD_5.9.c">Código Implementado</a><br></p>
<div class="highlight"><pre><code class="language-" data-lang="">/*------------------------------------------------------------------
 * Function:    Trap
 * Purpose:     Use trapezoidal rule to estimate definite integral
 * Input args:  
 *    a: left endpoint
 *    b: right endpoint
 *    n: number of trapezoids
 * Return val:
 *    approx:  estimate of integral from a to b of f(x)
 */
double Trap(double a, double b, int n, int thread_count, int *iterations) {
   double  h, approx;
   int  i;

   h = (b-a)/n; 
   approx = (f(a) + f(b))/2.0; 
#  pragma omp parallel for num_threads(thread_count) \
      reduction(+: approx) schedule(runtime)
   for (i = 1; i &lt;= n-1; i++) {
     approx += f(a + i*h);
     iterations[i-1] = omp_get_thread_num();
   }
   approx = h*approx; 

   return approx;
}  /* Trap */
</code></pre></div>
<p><img src="/assets/pcd/img5.9.1.png" alt="Imagem5.9.1"></p>

<p>Se a clausula schedule é incluída e OMP_SCHEDULE é definida para guided, 
então aproximadamente n/thread_count iterações são atribuídas para uma thread, 
e sucessivos blocos de iterações consecutivas tem aproximadamente metade do 
tamanho do bloco anterior. Neste caso também a atribuição de iterações varia para cada execução.</p>

<p><img src="/assets/pcd/img5.9.2.png" alt="Imagem5.9.2"></p>

<blockquote>
<p><strong><div class='text-danger'>5.10.</div></strong></p>
</blockquote>

<p></p>

<blockquote>
<p><strong>5.11.</strong> Recall that in C, a function that takes a two-dimensional array argument must
   specify the number of columns in the argument list, so it is quite common
   for C programmers to only use one-dimensional arrays, and to write explicit
   code for converting pairs of subscripts into a single dimension. Modify the
   OpenMP matrix-vector multiplication so that it uses a one-dimensional array
   for the matrix.</p>
</blockquote>
<div class="highlight"><pre><code class="language-" data-lang=""># pragma omp parallel for num_thread(thread_count) /
default(none) private(i, j) shared(A, x, y, m, n)

for (i = 0; i &lt; m; i++) {
    y[i] = 0.0;
    for (j = 0; j &lt; n; j++)
        //y[i] += A[i][j] * x[j];
        y[i] += A[i * n + j] * x[j];
}
</code></pre></div>
<blockquote>
<p><strong>5.12.</strong> Download the source file omp mat vect rand split.c from the book’s web-
site. Find a program that does cache profiling (e.g., Valgrind [49]) and compile
the program according to the instructions in the cache profiler documentation.
(For example, with Valgrind you will want a symbol table and full optimiza-
tion. (With gcc use, gcc − g − O2 . . . ). Now run the program according to
the instructions in the cache profiler documentation, using input k × (k · 10 6 ),
(k · 10 3 ) × (k · 10 3 ), and (k · 10 6 ) × k. Choose k so large that the number of
level 2 cache misses is of the order 10 6 for at least one of the input sets
of data.</p>

<p><strong>a.</strong> How many level 1 cache write-misses occur with each of the three inputs?<br>
<strong>b.</strong> How many level 2 cache write-misses occur with each of the three inputs?<br>
<strong>d.</strong> How many level 1 cache read-misses occur with each of the three inputs?<br>
<strong>e.</strong> How many level 2 cache read-misses occur with each of the three inputs?<br></p>
</blockquote>

<p>A ordem das matrizes são 8 x 8.000.000, 8.000 x 8.000 e 8.000.000 x 8. 
Os resultados obtidos usando o valgrind estão apresentados a seguir:</p>

<p><img src="/assets/pcd/img5.12.1.png" alt="Imagem5.12.1"></p>

<blockquote>
<p><strong>c.</strong> Where do most of the write-misses occur? For which input data does the
program have the most write-misses? Can you explain why?</p>
</blockquote>

<p>O maior numero de write-misses ocorre com a matriz de ordem 8.000.000 x 8. 
Neste sistema o array y tem ordem de 8.000.000, enquanto que nos outros 
sistemas sua ordem é de 8.000 e 8 respectivamente. Entre as variáveis A, x e y, y 
é a única variável que é escrita pelo código.</p>

<blockquote>
<p><strong>f.</strong> Where do most of the read-misses occur? For which input data does the
program have the most read-misses? Can you explain why?</p>
</blockquote>

<p>A maior quantidade de read-misses ocorre com a matriz de ordem 8 x 8.000.000. 
Cada elemento do array A vai ser lido uma única vez com os três inputs e, 
para cada input, A tem 64.000.000 de elementos. Os updates y[i] += … serão 
executados exatamente 64.000.000 de vezes e, como antes do loop interno ser executado y[i] 
é inicializado e provavelmente já está na cache, não causarão read-misses. As leituras de x[j] 
podem causar cache misses e no sistema de 8 x 8.000.000, x tem 8.000.000 de elementos, 
ao contrário dos outros dois sistemas com 8.000 e 8 elementos.</p>

<blockquote>
<p><strong>g.</strong> Run the program with each of the three inputs, but without using the cache
profiler. With which input is the program the fastest? With which input is
the program the slowest? Can your observations about cache misses help
explain the differences? How?</p>
</blockquote>

<p><code>Threads ---- 8 x 8.000.000 ---- 8.000 x 8.000 ---- 8.000.000 x 8</code><br>
<code>1 ---------- 0.43s ------------ 0.36s ------------ 0.42s</code><br></p>

<p>O programa mais lento é o com a matriz de ordem 8 x 8.000.000 e o mais rápido com a matriz de 
ordem 8.000 x 8.000.<br>
Read-misses tendem a ser mais custoso que write-misses. 
Quando um programa necessita de dados para executar uma computação, 
ele pode tanto tentar executar alguma outra computação ou esperar pelos dados. 
Os dados criados por um write podem frequentemente ser enfileirados e a computação pode prosseguir.<br>
O programa com a matriz de ordem 8.000.000 x 8 tem muito mais 
write-misses que o programa com a matriz de ordem 8.000 x 8.000. 
A quantidade de L2 read-misses entre os dois programas é idêntica e a diferença 
de L1 read-misses é muito menos custosa que L2 read-misses. Portanto o programa 
com a matriz de ordem 8.000 x 8.000 é mais rápido.</p>

<blockquote>
<p><strong>5.13.</strong> Recall the matrix-vector multiplication example with the 8000 × 8000 input.
   Suppose that thread 0 and thread 2 are assigned to different processors. If
   a cache line contains 64 bytes or 8 double s, is it possible for false sharing
   between threads 0 and 2 to occur for any part of the vector y ? Why? What
   about if thread 0 and thread 3 are assigned to different processors; is it possible
   for false sharing to occur between them for any part of y ?</p>
</blockquote>

<p>Com 8000 elementos y será particionando (aproximadamente) como segue:</p>

<p>Thread 0: y[0], y[1]       , … , y[1999]
Thread 1: y[2000],  y[2001] , … , y[3999]
Thread 2: y[4000],  y[4001] , … , y[5999]
Thread 3: y[6000],  y[6001] , … , y[7999]</p>

<p>Para ocorrer falso-compartilhamento entre as threads 0 e 2, deve haver 
elementos de y que pertencem à mesma linha de cache, mas associadas à threads 
diferentes. Na thread 0, a linha de cache que está mais &quot;próxima&quot; dos elementos 
associados à thread 2 é a linha que contém y[1999]. Mas mesmo que este seja o 
primeiro elemento da linha de cache, o índice mais alto possível para um elemento 
de y que pertence a esta linha é 2006:</p>

<p><code>y[1999]   y[2000]   y[2001]   y[2002]   y[2003]   y[2004]   y[2005]   y[2006]</code></p>

<p>Já que o menor index de um elemento de y associado à thread 2 é 4000, não existe 
a possibilidade de uma linha de cache ter elementos que pertencem tanto à thread 0 quanto à thread 2. 
Raciocínio similar se aplica às threads 0 e 3.</p>

<blockquote>
<p><strong>5.14.</strong> Recall the matrix-vector multiplication example with an 8 × 8, 000, 000
   matrix. Suppose that double s use 8 bytes of memory and that a cache line is 64
   bytes. Also suppose that our system consists of two dual-core processors.</p>
</blockquote>

<p>Verificando a localização de y[0] na primeira linha de cache contendo todo ou parte de y, 
vemos que y pode ser distribuído entre as linhas de cache de 8 formas diferentes. 
Se y[0] é o primeiro elemento da linha de cache, então a distribuição de y na cache será:</p>

<p><code>1ª linha: y[0]    y[1]    y[2]    y[3]    y[4]    y[5]    y[6]    y[7]</code></p>

<p>Se y[0] é o segundo elemento da linha de cache, então a distribuição será:</p>

<p><code>1ª linha: ----    y[0]    y[1]    y[2]    y[3]    y[4]    y[5]    y[6]</code><br>
<code>2ª linha: y[7]    ----    ----    ----    ----    ----    ----    ----</code></p>

<p>Se y[0] é o último elemento da primeira linha, então a distribuição será:</p>

<p><code>1ª linha: ----    ----    ----    ----    ----    ----    ----    y[0]</code><br>
<code>2ª linha: y[1]    y[2]    y[3]    y[4]    y[5]    y[6]    y[7]    ----</code></p>

<blockquote>
<p><strong>a.</strong> What is the minimum number of cache lines that are needed to store the
vector y ?</p>
</blockquote>

<p>Do primeiro exemplo vemos que é possível que y caiba em uma única linha de cache.</p>

<blockquote>
<p><strong>b.</strong> What is the maximum number of cache lines that are needed to store the
vector y ?</p>
</blockquote>

<p>No máximo ele ocupará duas linhas de cache.</p>

<blockquote>
<p><strong>c.</strong> If the boundaries of cache lines always coincide with the boundaries of
8-byte double s, in how many different ways can the components of y be
assigned to cache lines?</p>
</blockquote>

<p>Se os limites sempre coincidem, sempre haverá apenas uma possibilidade.</p>

<blockquote>
<p><strong>d.</strong> If we only consider which pairs of threads share a processor, in how
many different ways can four threads be assigned to the processors in our
computer? Here, we’re assuming that cores on the same processor share
cache.</p>
</blockquote>

<p>Podemos escolher 2 das threads e atribuí-las a um dos processadores: 
0 e 1, 0 e 2, 0 e 3 ou 0 e 4. Então existem 4 atribuições possíveis das threads para os processadores.</p>

<blockquote>
<p><strong>e.</strong> Is there an assignment of components to cache lines and threads to proces-
sors that will result in no false-sharing in our example? In other words, is it
possible that the threads assigned to one processor will have their compo-
nents of y in one cache line, and the threads assigned to the other processor
will have their components in a different cache line?</p>
</blockquote>

<p>Sim. Supondo que as threads 0 e 1 compartilham um processador e 
as threads 2 e 3 compartilham outro. Então se y[0], y[1], y[2] e y[3] 
estão em uma linha de cache e y[4], y[5], y[6] e y[7] estão em outra, 
qualquer escrita pela thread 0 ou 1 não irá invalidar a linha contendo 
os dados na linha de cache das threads 2 e 3. Da mesma forma, escritas 
por 2 e 3 não irão invalidar os dados na cache de 0 e 1.</p>

<blockquote>
<p><strong>f.</strong> How many assignments of components to cache lines and threads to
processors are there?</p>
</blockquote>

<p>Para cada uma das 4 atribuições de threads para processadores, 
existem 8 atribuições possíveis de y para linhas de cache. 
Portanto temos um total de 4 * 8 = 32 atribuições.</p>

<blockquote>
<p><strong>g.</strong> Of these assignments, how many will result in no false sharing?</p>
</blockquote>

<p>Apenas uma possibilidade, aquela que é apresentada na letra e).</p>

<blockquote>
<p><strong><div class='text-danger'>5.15.</div></strong></p>
</blockquote>

<p></p>

<blockquote>
<p><strong><div class='text-danger'>5.16.</div></strong></p>
</blockquote>
</span>

      </div>
      <div class="anuncio">
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <!-- Dudevictor github -->
    <ins class="adsbygoogle"
         style="display:block"
         data-ad-client="ca-pub-9976909752880073"
         data-ad-slot="9516328345"
         data-ad-format="auto"></ins>
    <script>
        (adsbygoogle = window.adsbygoogle || []).push({});
    </script>
    
</div>
      <div class="content-panel feedback">
        Did you like this page? Share or leave a comment below!<br />
        
        <div class="share">
          <!-- Go to www.addthis.com/dashboard to customize your tools -->
          <div class="addthis_sharing_toolbox"></div>
        </div>
        
      </div>

      
      <div class="content-panel comments">
        <div id="disqus_thread">
          <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
          <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
        </div>
      </div>
      


      <div class="content-panel related col-md-12">
        
        
        <div class="related-header">
          <a href=" /en/projects/processamento-digital-imagens/ ">Suggested Pages</a>
        </div>
        <div class="title">
          <a href=" /en/projects/processamento-digital-imagens/ ">Digital Image Processing</a>

        </div>
        <div class="excerpt">
          
          <p>Processing algorithms and image treatment with OpenCV</p>

          
          <br/><a href=" /en/projects/processamento-digital-imagens/ ">Continue Reading</a>
        </div>
        
      </div>

    </div>

    <div class="anuncio-lateral pull-right">
    <div class="conteudo-anuncio-lateral">
        
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <!-- Lateral Responsivo -->
        <ins class="adsbygoogle"
             style="display:block"
             data-ad-client="ca-pub-9976909752880073"
             data-ad-slot="1336169546"
             data-ad-format="auto"></ins>
        <script>
            (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
        
    </div>
</div>

  </div>



</div>


<script type="text/javascript">
/* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
function disqus_config() { this.experiment.enable_scroll_container = true; }
var disqus_shortname = "dudevictorgithub"; // required: replace example with your forum shortname
/* * * DON'T EDIT BELOW THIS LINE * * */
(function() {
  var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();
</script>


      </div>
    </div>

    <div class="footer clearfix">
    <div class="col-md-6">
        Copyright © 2016 by <a href="http://github.com/dudevictor">dudevictor</a>.
        All rights reserved.<br>Theme by <a href="https://twitter.com/_JacobTomlinson">Jacob
        Tomlinson</a>
    </div>
    <div class="col-md-6">
        &lt;/&gt; on <a href="https://github.com/dudevictor/dudevictor.github.io">Github</a> &nbsp;<i class="fa fa-github-alt"></i>
    </div>
</div>

<script src="//code.jquery.com/jquery-1.11.0.min.js"></script>
<script src="/js/bootstrap.min.js"></script>
<script src="/js/jquery.mmenu.all.min.js"></script>
<script src="/js/highlight.min.js"></script>

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&locale=br" type="text/javascript"></script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  "HTML-CSS": { linebreaks: { automatic: true, width: "90% container" } },
  "SVG": { linebreaks: { automatic: true, width: "90% container" } }
});
</script>


<script>hljs.initHighlightingOnLoad();</script>
<script type="text/javascript">
   $(document).ready(function() {
      var API = $("#my-menu").mmenu({
          counters		: true,
          dividers		: {
              fixed 			: true
          },
          navbar 			: {
              title			: ''
          },
          navbars			: [
              {
                  position	: 'top',
                  content : ['<span>José Victor Alves de Souza</span>']
              },
              {
                  position	: 'top'
              },
              {
                  position	: 'bottom',
                  content 	: ["<div class='language-links'><a  href='/projects/programacao-concorrente/shared-memory-with-openmp/'>pt-BR</a><a class='active' href='/en/projects/programacao-concorrente/shared-memory-with-openmp/'>en</a></div>"]
              }
          ]
      }).data( 'mmenu' );

       API.bind( "closed", function() {
          $(".menu-button").show();
          $("#at4-share, #at-share-dock").each(function() {
              $(this).removeClass("hide");
          });
      });

       $(".menu-button").click(function (e) {
           e.preventDefault();
           API.open();
           $(".menu-button").hide();
           $("#at4-share, #at-share-dock").each(function () {
               $(this).removeClass("at4-show").addClass("hide");
           });

       });
   });
</script>

    </body>
</html>
